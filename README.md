# Pipeline to generate ML dataframes for predicting docking scores.

The main script `src/merge_desc_and_scores.py` parses raw docking scores, merges with modred descriptors, and dumps ML dataframes for every receptor/target available in a docking results file. The scores and descriptors are merged on the canonical (drug) SMILES. ML files follow the same naming convention: `ml.<target_name>.csv` (e.g., `ml.ADRP_pocket1_dock.csv`).

A subset of `ml.ADRP_pocket1_dock.csv` from March 30th:
<img src="figs/ML-df-example.png" alt="drawing" height="200"/>

Histograms of docking scores (`reg` column) of two different targets. Higher values indicate better docking.

<img src="figs/dock.score.bin.ml.ADRP_pocket1_dock.png" alt="drawing" width="400"/> <img src="figs/dock.score.bin.ml.PLPro_pocket6_dock.png" alt="drawing" width="400"/>

- `reg`: regression score. Raw docking scores are transformed with:
```python
reg = np.clip(df[reg_raw], a_min=None, a_max=0) * (-1)
```
`reg` are the transformed scores where larger values indicate better docking.
- `cls`: classification score. `cls` was generated by computing the 0.975 quantile (dashed vertical line in a histogram) and using the value to threshold `reg` for binary classification task (values larger that the quantile are labeled with 1).
- `binner`: per-filter classifier. `binner` was generated by theresholding `reg` as follows: 0 if reg_value < 2 else 1 <br>
Certain targets exhibits a large number of non-docking drugs as shown for `PLPro_pocket6` (large count around 0 in the histogram). To facilitate learning of ML predictors (`reg` and `cls`), we can build a binner classifier that serves a pre-filter that aims to filter out those non-docking drugs before building models for `reg` and `cls`.
- `name`: drug name
- `smiles`: canonical SMILES string

## Docking Scores
Raw docking scores from MD simulations are stored in Box `2019-nCoV/drug_screening/raw_data/`. Every new batch of simulation results is dumped into `2019-nCoV/drug_screening/raw_data/docking_data_<month>_<day>` (e.g., `2019-nCoV/drug_screening/raw_data/docking_data_march_30`).
Each batch is structured with drug SMILES in the first column and receptors/targets in the subsequent columns. The values are the docking scores. For more info refer https://github.com/2019-ncovgroup/HTDockingDataInstructions.

<img src="figs/docking-results-example.png" alt="drawing" height="200"/>

## Generating ML dataframes
To start generating ML dataframes you need to data files:
- Docking scores (`2019-nCoV/drug_screening/raw_data/docking_data_<month>_<day>`)
- Descriptors (`2019-nCoV/drug_screening/descriptors/ena+db.desc.parquet`)

Launch `src/merge_desc_scores.py` to generate dataframes:
```shell script
python src/merge_desc_scores.py --scores_path data/raw/raw_data/docking_data_march_30/docking_data_out_v2.0.can.parquet --scores_path data/processed/descriptors/smi.desc.parquet --par_jobs 16
```
Note that `par_jobs` argument uses the `joblib` python package to parallelize the processing.

## Descriptors
The original modred descriptors are stored in Box `2019-nCoV/drug_screening/ena+db.desc.gz`. This file requires some pre-processing (duplicates, bad rows, NaNs, casting). This needs to be done only once. The clean version of descriptors can be found in Box `2019-nCoV/drug_screening/descriptors/ena+db.desc.parquet`. If you need to generate the descriptors from the original, follow the steps below.

- Clean and canonicalize smiles `ena+db.smi` using `src/clean_smiles.py` (updated file is in `2019-nCoV/drug_screening/descriptors/ena+db.smi.can`)
- Clean descriptors `ena+db.desc` using `src/clean_desc.py` (updated file is in `2019-nCoV/drug_screening/descriptors/ena+db.desc.parquet`)
- Merge smiles and descriptors using `src/merge_smi_desc.py` (updated file is in `2019-nCoV/drug_screening/descriptors/smi.desc.parquet`)

<img src="figs/smi-desc-df.png" alt="drawing" height="220"/>
