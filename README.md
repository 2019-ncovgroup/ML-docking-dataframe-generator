Pipeline that generates ML dataframes for predicting docking scores (generated by high-throughput MD simulations).

The main script `merge_desc_and_scores.py` parses raw docking scores, merges with modred descriptors, and dumps ML dataframes for every Receptor/Target available in a docking results file. The scores and descriptors are merged on the canonical (drug) SMILES string. Every ML file follows the same naming convention: `ml.<target_name>.csv` (e.g., `ml.ADRP_pocket1_dock.csv`).

Below is `ml.ADRP_pocket1_dock.csv` from March 30 batch:
TODO

Below are representative histograms of docking scores (`reg` column) for two different targets. Higher values indicate better docking.

`reg`: regression score. The raw simulation scores contain negative values. The raw values are converted to postive as follows: reg = np.clip(df[reg_raw], a_min=None, a_max=1) * (-1) + 1
`reg` are the transformed scores where larger values indicate better docking.
`cls`: classification score. This column was generated by computing the 0.975 quantile (the dashed vertical line in a histogram) and using the value to threshold `reg` for binary classification task.
`binner`: per-filter classifier. This column was generated by theresholding `reg` as follows: 0 if reg_value < 2 else 1
Certain targets exhibits a large number of non-docking drugs (the large count around 0 in the histogram). To facilitate learning of ML predictors, we attempt to remove these non-docking drugs by filtering out those drugs with the binner classifier.
`name`: drug name
`smiles`: canonical SMILES string

## Docking Scores
Raw docking scores from MD simulations are stored in Box `2019-nCoV/drug_screening/raw_data/`. Every new batch of simulation results is dumped into `2019-nCoV/drug_screening/raw_data/docking_data_<month>_<date>`. For example: `2019-nCoV/drug_screening/raw_data/docking_data_march_30`.
Each batch is structed as follows: the first column is the drug SMILES, the next columns are the receptors, and values are the scores.
A subset of a results file is shown below:
TODO

## Descriptors
The original modred descriptors are stored in Box `2019-nCoV/drug_screening/ena+db.desc.gz`. This file required some pre-processing (removing duplicates, bad rows, NaNs, casting). This needs to be done only once. The clean version of descriptors can be found in a Box folder `2019-nCoV/drug_screening/descriptors/ena+db.desc.parquet`. The first column is the drug name and the subsequent columns are modred descriptors prefixed with `.mod`. 

The descriptors in `ena+db.desc.parquet` are merged with `ena+db.smi.can.csv` on the (drug) `name` to bring the SMILES into the descriptors dataframe.

Since scores and decriptors

The main script merges descriptors and docking scores on cannonicalized smiles. The raw descriptors (`ena+db.desc`) and docking results (`docking_data_out*.csv`) require some pre-processing before using the main script (`merge_desc_and_score.py`). The step-by-step pipeline is as follows: 

1. The first column of every docking results file is `smiles`. This column is used later in `merge_desc_scores.py` to merge docking scores with descriptors. We need to make sure that each string in `smiles` is canonicalized before merging. Here, we canonicalize the `smiles` using `canon_smiles.py`.
```shell script
python src/canon_smiles.py data/raw/raw_data/docking_data_march_30/docking_data_out_v2.0.csv
```

2. The next step is to use `merge_desc_and_scores.py` to create ML dataframe for every target.
```shell script
python src/merge_desc_scores.py data/raw/raw_data/docking_data_march_30/docking_data_out_v2.0.csv
```

