# Pipeline that generates ML dataframes for predicting docking scores.

The main script `src/merge_desc_and_scores.py` parses raw docking scores, merges with modred descriptors, and dumps ML dataframes for every receptor/target available in a docking results file. The scores and descriptors are merged on the canonical (drug) SMILES string. Every ML file follows the same naming convention: `ml.<target_name>.csv` (e.g., `ml.ADRP_pocket1_dock.csv`).

A subset of `ml.ADRP_pocket1_dock.csv` from March 30 batch:
TODO

Representative histograms of docking scores (`reg` column) for two different targets. Higher values indicate better docking.

- `reg`: regression score. Raw docking are transformed as follows: <br>
reg = np.clip(df[reg_raw], a_min=None, a_max=1) * (-1) + 1 <br>
`reg` are the transformed scores where larger values indicate better docking.
- `cls`: classification score. `cls` was generated by computing the 0.975 quantile (the dashed vertical line in a histogram) and using the value to threshold `reg` for binary classification task (values larger that the quantile are labeled with 1).
- `binner`: per-filter classifier. `binner` was generated by theresholding `reg` as follows: 0 if reg_value < 2 else 1 <br>
Certain targets exhibits a large number of non-docking drugs as shown for `PLPro_pocket6` (large count around 0 in the histogram). To facilitate learning of ML predictors (`reg` and `cls`), we can build a binner classifier that serves a pre-filter that aims to filter out those non-docking drugs before building models for `reg` and `cls`.
- `name`: drug name
- `smiles`: canonical SMILES string

## Docking Scores
Raw docking scores from MD simulations are stored in Box `2019-nCoV/drug_screening/raw_data/`. Every new batch of simulation results is dumped into `2019-nCoV/drug_screening/raw_data/docking_data_<month>_<date>`. For example: `2019-nCoV/drug_screening/raw_data/docking_data_march_30`.
Each batch is structured with drug SMILES in the first column and receptors/targets in the subsequent columns. The values are the scores.

TODO

## Generating ML dataframes
Launch `src/merge_desc_scores.py` to generate the dataframes. For example:
```shell script
python src/merge_desc_scores.py --scores_path data/raw/raw_data/docking_data_march_30/docking_data_out_v2.0.can.parquet --scores_path data/processed/descriptors/smi.desc.parquet --par_jobs 16
```
Note that `par_jobs` argument uses the `joblib` python package to parallelize the processing.

## Descriptors
The original modred descriptors are stored in Box `2019-nCoV/drug_screening/ena+db.desc.gz`. This file requires some pre-processing (removing duplicates, bad rows, NaNs, casting). This needs to be done only once. The clean version of descriptors can be found in a Box `2019-nCoV/drug_screening/descriptors/ena+db.desc.parquet`. The first column is the drug name and the subsequent columns are modred descriptors prefixed with `.mod`.

You need to follow these steps if you wish to generate the descriptors:
- Clean and canonicalize smiles `ena+db.smi` using `src/clean_smiles.py` (updated file is in `2019-nCoV/drug_screening/descriptors/ena+db.smi.can`)
- Clean descriptors in `ena+db.desc` using `src/clean_desc.py` (updated file is in `2019-nCoV/drug_screening/descriptors/ena+db.desc.parquet`)
- Merge smiles and descriptors using `src/merge_smi_desc.py` (updated file is in `2019-nCoV/drug_screening/descriptors/smi.desc.parquet`)

The descriptors in `ena+db.desc.parquet` are merged with `ena+db.smi.can.csv` on the (drug) `name` to bring the SMILES into the descriptors dataframe.

Since scores and decriptors

The main script merges descriptors and docking scores on cannonicalized smiles. The raw descriptors (`ena+db.desc`) and docking results (`docking_data_out*.csv`) require some pre-processing before using the main script (`merge_desc_and_score.py`). The step-by-step pipeline is as follows: 

1. The first column of every docking results file is `smiles`. This column is used later in `merge_desc_scores.py` to merge docking scores with descriptors. We need to make sure that each string in `smiles` is canonicalized before merging. Here, we canonicalize the `smiles` using `canon_smiles.py`.
```shell script
python src/canon_smiles.py data/raw/raw_data/docking_data_march_30/docking_data_out_v2.0.csv
```

2. The next step is to use `merge_desc_and_scores.py` to create ML dataframe for every target.
```shell script
python src/merge_desc_scores.py data/raw/raw_data/docking_data_march_30/docking_data_out_v2.0.csv
```

